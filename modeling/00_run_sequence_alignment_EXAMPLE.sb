#!/bin/bash
################################
#SBATCH --time=12:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem=48G
################################

# This is the first step of an AlphaFold run, where we run
# multiple sequence alignment. Because it doesn't require GPU,
# we can split it off to help decrease our total time in the queue

# Set the array size -- this is the number of files to process
#SBATCH --array=1-<NUM_FILES>

# First, purge and load modules
module purge
module load AlphaFold3/3.0.1-foss-2023a-CUDA-12.4.0 ## Could change

# Then define the parameter and database global variables
export MODEL_WEIGHTS="/mnt/research/Walker_Lab_Research/alphaFold3"
export DATABASES="/mnt/research/common-data/alphafold/database_3/"

# Set the directory where the jsons are found
DATADIR=<DATA_DIR_IN_QUOTES> # No slash at the end

# Set the list of files to iterate over
readarray -t files <${DATADIR}/file_list

# Run an array of AlphaFold calls
run_alphafold.py \
  --norun_inference \
  --json_path=${DATADIR}/${files[$SLURM_ARRAY_TASK_ID-1]} \
  --model_dir=${MODEL_WEIGHTS} \
  --db_dir=${DATABASES} \
  --output_dir=${DATADIR} # Put them in the same original directory to ease pipelining
